import * as tfconv from '@tensorflow/tfjs-converter';
import * as tf from '@tensorflow/tfjs-core';

interface Point2D {
    x: number;
    y: number;
}
interface Point3D {
    x: number;
    y: number;
    z: number;
}
declare type Coord2D = [number, number];
declare type Coord3D = [number, number, number];
declare type Matrix3x3 = [Coord3D, Coord3D, Coord3D];
declare type Quaternion = [number, number, number, number];
interface Size {
    width: number;
    height: number;
}
interface Rect {
    xy: Point2D;
    size: Size;
}
declare type Box = [Coord2D, Coord2D];
declare type ImageInput = ImageData | ImageBytes | HTMLCanvasElement;
interface ImageBytes {
    data: Uint8Array;
    width: number;
    height: number;
}
declare function rectIoU(r0: Rect, r1: Rect): number;
declare function boxIoU(b0: Box, b1: Box): number;

interface BodyDetection {
    points: Coord2D[];
    box: Box;
    score: number;
}
interface BodyCircle {
    center: Coord2D;
    top: Coord2D;
}
declare class BodyDetector {
    private model;
    private modelSize;
    private modelRatio;
    private anchorsX;
    private anchorsY;
    private anchorsData;
    private posesMax;
    private iouThresh;
    private scoreThresh;
    readonly keypointCount = 4;
    constructor(model: tfconv.GraphModel, width: number, height: number);
    process(image: tf.Tensor4D): Promise<BodyDetection[]>;
    decodeBoxes(pred: tf.Tensor2D, anchors: [tf.Tensor1D, tf.Tensor1D], size: Size): tf.Tensor2D;
    buildAnchors(size: Size): Point2D[];
    prepare(): Promise<void>;
    dispose(): void;
}

interface PosePoint {
    pixel: Coord3D;
    metric: Coord3D;
    score: number;
    visibility: number;
}
interface PoseDetection {
    keypoints: PosePoint[];
    score: number;
    center: Coord2D;
    top: Coord2D;
    debug: {
        center: Coord2D;
        top: Coord2D;
        box: Box;
        radius: number;
        angle: number;
    };
}
declare class PoseDetector {
    private model;
    private modelSize;
    private sizeFactor;
    constructor(model: tfconv.GraphModel, width: number, height: number);
    process(image: tf.Tensor4D, detections: BodyCircle[]): Promise<PoseDetection[]>;
    refinePoints(points: Coord3D[], heatmap4D: tf.Tensor4D): Coord3D[];
    prepare(): Promise<void>;
    dispose(): Promise<void>;
}

interface FilterParams {
    minCutOff: number;
    minCutOffD: number;
    beta: number;
}
declare class PoseFilter {
    protected freq: number;
    readonly pixelParams: FilterParams;
    readonly metricParams: FilterParams;
    readonly boxParams: FilterParams;
    readonly scoreCutOff = 1;
    readonly visibilityCutOff = 1;
    protected raw?: PoseDetection;
    protected smooth?: PoseDetection;
    protected der?: PoseDetection;
    protected time: number;
    filter(val: PoseDetection, time: number, scale?: number): PoseDetection;
    protected filterKeypoints(val: PosePoint[], raw: PosePoint[], der: PosePoint[], smooth: PosePoint[], scale: number): void;
    protected filterCoord3D(val: Coord3D, raw: Coord3D, der: Coord3D, smooth: Coord3D, scale: number, params: FilterParams): void;
    protected filterCoord2D(val: Coord2D, raw: Coord2D, der: Coord2D, smooth: Coord2D, scale: number, params: FilterParams): void;
    protected reset(): void;
    protected alpha(cutOff: number): number;
    protected clonePose(v: PoseDetection): PoseDetection;
}

declare class PoseTracker {
    protected bodyDetector?: BodyDetector;
    protected poseDetector?: PoseDetector;
    protected poseModule?: any;
    protected poseAligner?: any;
    protected bodyTracks: BodyCircle[];
    protected poseFilters: PoseFilter[];
    protected angle: number;
    protected ratio: number;
    protected near: number;
    readonly poseScore = 0.6;
    readonly alignScore = 0.9;
    readonly alignVisibility = 0.9;
    protected skipCount: number;
    readonly skipMax = 2;
    process(input: ImageInput, timestamp?: number): Promise<PoseDetection[]>;
    setCamera(angle: number, ratio: number, near?: number): void;
    init(token: string, root?: string, cache?: boolean, backend?: "webgl" | "cpu"): Promise<void>;
    reset(): void;
    prepare(): Promise<void>;
    dispose(): void;
}

interface FaceDetection {
    rect: Rect;
    score: number;
    keypoints?: Point2D[];
}
declare class FaceDetector {
    private model;
    private modelSize;
    private modelRatio;
    private anchors;
    private anchorsData;
    private size;
    private facesMax;
    private iouThresh;
    private scoreThresh;
    private keypointCount;
    constructor(model: tfconv.GraphModel, width: number, height: number);
    process(image: tf.Tensor4D, keypoints?: boolean): Promise<FaceDetection[]>;
    decodeBoxes(pred: tf.Tensor2D, anchors: tf.Tensor2D, size: tf.Tensor1D): tf.Tensor2D;
    buildAnchors(size: Size): [number, number][];
    prepare(): Promise<void>;
    dispose(): void;
}
declare enum FacePoints {
    EyeR = 0,
    EyeL = 1,
    Nose = 2,
    Mouth = 3,
    EarR = 4,
    EarL = 5
}

interface FaceBox {
    rect: Rect;
    symmetry: [Point2D, Point2D];
}
interface MeshDetection {
    keypoints: Coord3D[];
    rect: [number, number, number, number];
    score: number;
}
declare class MeshDetector {
    private model;
    private modelSize;
    private modelHighP;
    private boxFactor;
    symmetryPoints: number[];
    constructor(model: tfconv.GraphModel, width: number, height: number);
    process(image: tf.Tensor4D, detections: FaceBox[]): Promise<{
        keypoints: Coord3D[];
        score: number;
        rect: [number, number, number, number];
    }[]>;
    prepare(): Promise<void>;
    dispose(): void;
}
declare function scaleMesh(mesh: MeshDetection, factor: number): MeshDetection;

interface FacePose {
    rotation: Quaternion;
    translation: Coord3D;
    scale: number;
    shapeScale: Coord3D;
}
declare class FaceTracker {
    protected faceDetector?: FaceDetector;
    protected meshDetector?: MeshDetector;
    protected faceModule?: any;
    protected faceAligner?: any;
    protected faceTracks: FaceBox[];
    protected faceFilters: any[];
    readonly meshScore = 0.9;
    process(input: ImageInput, timestamp?: number): Promise<MeshDetection[]>;
    align(model: Coord3D[]): FacePose | undefined;
    alignTransform(): FacePose | undefined;
    metricPoints(): Coord3D[] | undefined;
    referencePoints(): Coord3D[] | undefined;
    backprojPoints(): Coord3D[] | undefined;
    setCamera(angle: number, ratio: number, near: number): void;
    init(token: string, root?: string, cache?: boolean, highp?: boolean, backend?: "webgl" | "cpu"): Promise<void>;
    reset(): void;
    prepare(): Promise<void>;
    dispose(): void;
}

declare const meshDesc: {
    [key: string]: number[];
};
declare const meshTriangles: number[];
declare const meshUV: Coord2D[];
declare const meshReference: Coord3D[];

declare class MeanColor {
    canvas?: HTMLCanvasElement;
    protected context: CanvasRenderingContext2D | null;
    constructor();
    mean(image: HTMLCanvasElement): number[] | undefined;
    brightness(image: HTMLCanvasElement): number | undefined;
    dispose(): void;
}

export { BodyCircle, BodyDetection, BodyDetector, Box, Coord2D, Coord3D, FaceBox, FaceDetection, FaceDetector, FacePoints, FacePose, FaceTracker, ImageBytes, ImageInput, Matrix3x3, MeanColor, MeshDetection, MeshDetector, Point2D, Point3D, PoseDetection, PoseDetector, PosePoint, PoseTracker, Quaternion, Rect, Size, boxIoU, meshDesc, meshReference, meshTriangles, meshUV, rectIoU, scaleMesh };
